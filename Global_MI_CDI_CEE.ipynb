{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f8b1b5-2501-49d0-9116-73b3a0f2360f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MI with CDI Paper method (Faiz, M. A. et al. A composite drought index developed for detecting large-scale drought characteristics. Journal of Hydrology 605, 127308 (2022))\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "# Function to cap MI values at -1 and +1\n",
    "def cap_mi_values(array):\n",
    "    array = np.where(array < -1, -1, array)\n",
    "    array = np.where(array > 1, 1, array)\n",
    "    return array\n",
    "\n",
    "# Load the precipitation data from NetCDF file\n",
    "precipitation_nc = xr.open_dataset('PR_Monthly_2000_23.nc')\n",
    "\n",
    "# Load the evapotranspiration data from NetCDF file\n",
    "evapotranspiration_nc = xr.open_dataset('2000_2023_monthly_E.nc')\n",
    "\n",
    "# Ensure both datasets have the same time range and spatial resolution\n",
    "precipitation_nc = precipitation_nc.sel(time=slice('2000-01-01', '2022-12-31'))\n",
    "evapotranspiration_nc = evapotranspiration_nc.sel(time=slice('2000-01-01', '2022-12-31'))\n",
    "\n",
    "# Interpolate evapotranspiration data to match the precipitation data grid\n",
    "evapotranspiration_nc = evapotranspiration_nc.interp(lat=precipitation_nc.lat, lon=precipitation_nc.lon, method=\"nearest\")\n",
    "\n",
    "# Calculate the mean precipitation and mean evapotranspiration over the entire period\n",
    "mean_precipitation = precipitation_nc['precipitation'].mean(dim='time')\n",
    "mean_evapotranspiration = evapotranspiration_nc['E'].mean(dim='time')\n",
    "\n",
    "# Calculate the standard MI for each month for each grid point using the new formula\n",
    "mi_standard = (precipitation_nc['precipitation'] - evapotranspiration_nc['E']) / (mean_precipitation - mean_evapotranspiration)\n",
    "\n",
    "# Apply the capping function to the MI values\n",
    "mi_standard_corrected = cap_mi_values(mi_standard)\n",
    "\n",
    "# Create a new xarray Dataset for the corrected MI\n",
    "mi_standard_corrected_ds = xr.Dataset(\n",
    "    {\n",
    "        \"MI_corrected\": ([\"time\", \"lat\", \"lon\"], mi_standard_corrected)\n",
    "    },\n",
    "    coords={\n",
    "        \"time\": precipitation_nc.time,\n",
    "        \"lat\": precipitation_nc.lat,\n",
    "        \"lon\": precipitation_nc.lon\n",
    "    }\n",
    ")\n",
    "\n",
    "# Save the corrected MI dataset to a new NetCDF file\n",
    "corrected_mi_filename = '/MI_CDI_Method.nc'\n",
    "mi_standard_corrected_ds.to_netcdf(corrected_mi_filename)\n",
    "\n",
    "print(\"Corrected Moisture Index has been calculated and saved to the NetCDF file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4352e318-aa62-4ea7-aad0-de214d445f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MI with Chinese paper Method (Zhou, W., Liu, G., Pan, J., Feng, X., 2005. Distribution of available soil water capacity in China. J. Geog. Sci. 15 (1), 3–12\n",
    "#Qian, W., Shan, X., Zhu, Y., 2011. Ranking regional drought events in China for 1960–2009. Advances in Atmospheric Sciences 28, 310–321.\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "# Function to cap MI values at -1 and +1\n",
    "def cap_mi_values(array):\n",
    "    array = np.where(array < -1, -1, array)\n",
    "    array = np.where(array > 1, 1, array)\n",
    "    return array\n",
    "\n",
    "# Load the precipitation data from NetCDF file\n",
    "precipitation_nc = xr.open_dataset('/PR_Monthly_2000_23.nc')\n",
    "\n",
    "# Load the evapotranspiration data from NetCDF file\n",
    "evapotranspiration_nc = xr.open_dataset('/2000_2023_monthly_E.nc')\n",
    "\n",
    "# Ensure both datasets have the same time range and spatial resolution\n",
    "precipitation_nc = precipitation_nc.sel(time=slice('2000-01-01', '2022-12-31'))\n",
    "evapotranspiration_nc = evapotranspiration_nc.sel(time=slice('2000-01-01', '2022-12-31'))\n",
    "\n",
    "# Interpolate evapotranspiration data to match the precipitation data grid\n",
    "evapotranspiration_nc_interp = evapotranspiration_nc.interp(lat=precipitation_nc.lat, lon=precipitation_nc.lon, method=\"nearest\")\n",
    "\n",
    "# Avoid division by zero in MI calculation\n",
    "precipitation_values = precipitation_nc['precipitation'].values\n",
    "evapotranspiration_values = evapotranspiration_nc_interp['E'].values\n",
    "\n",
    "# Replace zero precipitation values with a small number (e.g., 1e-10) to avoid division by zero\n",
    "precipitation_values = np.where(precipitation_values == 0, 1e-10, precipitation_values)\n",
    "\n",
    "# Calculate the standard MI for each month for each grid point\n",
    "mi_standard = (precipitation_values - evapotranspiration_values) / precipitation_values\n",
    "\n",
    "# Apply the capping function to the MI values\n",
    "mi_standard_corrected = cap_mi_values(mi_standard)\n",
    "\n",
    "# Create a new xarray Dataset for the corrected MI\n",
    "mi_standard_corrected_ds = xr.Dataset(\n",
    "    {\n",
    "        \"MI_corrected\": ([\"time\", \"lat\", \"lon\"], mi_standard_corrected)\n",
    "    },\n",
    "    coords={\n",
    "        \"time\": precipitation_nc.time,\n",
    "        \"lat\": precipitation_nc.lat,\n",
    "        \"lon\": precipitation_nc.lon\n",
    "    }\n",
    ")\n",
    "\n",
    "# Save the corrected MI dataset to a new NetCDF file\n",
    "corrected_mi_filename = '/MI__Method.nc'\n",
    "mi_standard_corrected_ds.to_netcdf(corrected_mi_filename)\n",
    "\n",
    "print(\"Corrected Moisture Index has been calculated and saved to the NetCDF file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "741430f7-bed5-4a64-b0a8-04ff3b94ae81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common shape: (264, 720, 1440)\n",
      "CMDI data saved to NetCDF file successfully.\n"
     ]
    }
   ],
   "source": [
    "#CMDI Final with PCA (This is CDI_Main calculation) for our own settings we named them like this......\n",
    "#Please for accurate abbreviation, consult our published papers (A composite drought index developed for detecting large-scale drought characteristics;\n",
    "#Revisiting the composite drought index for improving drought monitoring\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Function to trim and reshape data\n",
    "def trim_and_reshape(data, common_shape):\n",
    "    trimmed_data = data[:common_shape[0], :common_shape[1], :common_shape[2]]\n",
    "    return trimmed_data.flatten()\n",
    "\n",
    "# Function to process and combine indices using PCA\n",
    "def process_chunk(mRAI_chunk, mMRA2_chunk, MI_chunk, common_shape):\n",
    "    mRAI_1d = trim_and_reshape(mRAI_chunk, common_shape)\n",
    "    mMRA2_1d = trim_and_reshape(mMRA2_chunk, common_shape)\n",
    "    MI_1d = trim_and_reshape(MI_chunk, common_shape)\n",
    "\n",
    "    # Combine data\n",
    "    data_combined = np.column_stack((mRAI_1d, mMRA2_1d, MI_1d))\n",
    "    \n",
    "    # Impute missing values\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    data_imputed = imputer.fit_transform(data_combined)\n",
    "    \n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components=1)\n",
    "    cmdi_pca = pca.fit_transform(data_imputed).flatten()\n",
    "\n",
    "    return cmdi_pca.reshape(common_shape)\n",
    "\n",
    "# Load data from NetCDF files\n",
    "mRAI_path = \"/.nc\" # is mRAI\n",
    "mMRA2_path = \"/.nc\" # here it is mWBAI\n",
    "MI_path = \"/.nc\" #MI \n",
    "\n",
    "mRAI_data = nc.Dataset(mRAI_path)\n",
    "mMRA2_data = nc.Dataset(mMRA2_path)\n",
    "MI_data = nc.Dataset(MI_path)\n",
    "\n",
    "# Extract variables\n",
    "mRAI = mRAI_data.variables['mRAI']\n",
    "mMRA2 = mMRA2_data.variables['mRAI']\n",
    "MI = MI_data.variables['MI_corrected']\n",
    "\n",
    "# Determine the common shape\n",
    "common_shape = (\n",
    "    min(mRAI.shape[0], mMRA2.shape[0], MI.shape[0]),\n",
    "    min(mRAI.shape[1], mMRA2.shape[1], MI.shape[1]),\n",
    "    min(mRAI.shape[2], mMRA2.shape[2], MI.shape[2])\n",
    ")\n",
    "\n",
    "print(f\"Common shape: {common_shape}\")\n",
    "\n",
    "# Create a new NetCDF file to save CMDI\n",
    "output_path = \"/CMDI_Main.nc\"\n",
    "with nc.Dataset(output_path, 'w', format='NETCDF4') as cmdi_nc:\n",
    "    # Create dimensions\n",
    "    cmdi_nc.createDimension('time', common_shape[0])\n",
    "    cmdi_nc.createDimension('lat', common_shape[1])\n",
    "    cmdi_nc.createDimension('lon', common_shape[2])\n",
    "    \n",
    "    # Create variables\n",
    "    times = cmdi_nc.createVariable('time', 'f8', ('time',))\n",
    "    lats = cmdi_nc.createVariable('lat', 'f8', ('lat',))\n",
    "    lons = cmdi_nc.createVariable('lon', 'f8', ('lon',))\n",
    "    cmdi_var = cmdi_nc.createVariable('CMDI', 'f8', ('time', 'lat', 'lon'))\n",
    "    \n",
    "    # Assign dimension data\n",
    "    times[:] = MI_data.variables['time'][:common_shape[0]]\n",
    "    lats[:] = MI_data.variables['lat'][:common_shape[1]]\n",
    "    lons[:] = MI_data.variables['lon'][:common_shape[2]]\n",
    "\n",
    "    # Process data in chunks to save memory\n",
    "    chunk_size = 10  # Adjust this to control memory usage\n",
    "    for start in range(0, common_shape[0], chunk_size):\n",
    "        end = min(start + chunk_size, common_shape[0])\n",
    "        mRAI_chunk = mRAI[start:end, :common_shape[1], :common_shape[2]]\n",
    "        mMRA2_chunk = mMRA2[start:end, :common_shape[1], :common_shape[2]]\n",
    "        MI_chunk = MI[start:end, :common_shape[1], :common_shape[2]]\n",
    "        \n",
    "        cmdi_chunk = process_chunk(mRAI_chunk, mMRA2_chunk, MI_chunk, (end-start, common_shape[1], common_shape[2]))\n",
    "        cmdi_var[start:end, :, :] = cmdi_chunk\n",
    "\n",
    "    # Add attributes\n",
    "    cmdi_nc.description = \"Composite Drought Index (CMDI)\" #CMDI is refer to CDI, we used differnt variables due to lengthy data calculations for multiple files \n",
    "    times.units = MI_data.variables['time'].units\n",
    "    lats.units = 'degrees_north'\n",
    "    lons.units = 'degrees_east'\n",
    "    cmdi_var.units = 'unitless'\n",
    "\n",
    "print(\"CMDI data saved to NetCDF file successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a809f77-cb05-432c-b4f4-4f37dc972712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted files saved successfully.\n"
     ]
    }
   ],
   "source": [
    "#CDI Weights multiply due to computation limitations \n",
    "import xarray as xr\n",
    "\n",
    "# File paths\n",
    "mRAI_path = \"/.nc\" # this mRAI\n",
    "mMRA2_path = \"/.nc\" #This is mBAI\n",
    "MI_path = \"/.nc\" # This MI\n",
    "\n",
    "# Open the NetCDF files\n",
    "mRAI_ds = xr.open_dataset(mRAI_path)\n",
    "mMRA2_ds = xr.open_dataset(mMRA2_path)\n",
    "MI_ds = xr.open_dataset(MI_path)\n",
    "\n",
    "# Extract the relevant data arrays\n",
    "mRAI_data = mRAI_ds['mRAI']\n",
    "mMRA2_data = mMRA2_ds['mRAI']\n",
    "MI_data = MI_ds['MI_corrected']\n",
    "\n",
    "# Define the common time period\n",
    "start_date = \"2000-01-01\"\n",
    "end_date = \"2021-12-31\"\n",
    "\n",
    "# Subset the data to the common time period\n",
    "mRAI_data = mRAI_data.sel(time=slice(start_date, end_date))\n",
    "mMRA2_data = mMRA2_data.sel(time=slice(start_date, end_date))\n",
    "MI_data = MI_data.sel(time=slice(start_date, end_date))\n",
    "\n",
    "# Apply the given weights\n",
    "mRAI_weighted = mRAI_data * 0.4\n",
    "mMRA2_weighted = mMRA2_data * 0.4\n",
    "MI_weighted = MI_data * 0.8\n",
    "\n",
    "# Save the weighted data arrays to new NetCDF files\n",
    "mRAI_weighted_ds = xr.Dataset({\"mRAI_weighted\": mRAI_weighted})\n",
    "mRAI_weighted_ds.to_netcdf(\"/mRAI_weighted.nc\")\n",
    "\n",
    "mMRA2_weighted_ds = xr.Dataset({\"mMRA2_weighted\": mMRA2_weighted})\n",
    "mMRA2_weighted_ds.to_netcdf(\"/mMRA2_weighted.nc\")\n",
    "\n",
    "MI_weighted_ds = xr.Dataset({\"MI_weighted\": MI_weighted})\n",
    "MI_weighted_ds.to_netcdf(\"/MI_weighted.nc\")\n",
    "\n",
    "print(\"Weighted files saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56687131-8eb3-4207-9421-8ab9adb491c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New NetCDF file CMDI.nc created successfully.\n"
     ]
    }
   ],
   "source": [
    "#CDI Weight Combine to make CMDI (CDI)\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "\n",
    "# File paths\n",
    "mRAI_weighted_file = '/mRAI_weighted.nc'\n",
    "mMRA2_weighted_file = '/mMRA2_weighted.nc'\n",
    "MI_weighted_file = '/MI_weighted.nc'\n",
    "CMDI_file = '/CDI.nc'\n",
    "\n",
    "# Open the NetCDF files\n",
    "mRAI_ds = nc.Dataset(mRAI_weighted_file, 'r')\n",
    "mMRA2_ds = nc.Dataset(mMRA2_weighted_file, 'r')\n",
    "MI_ds = nc.Dataset(MI_weighted_file, 'r')\n",
    "\n",
    "# Create a new NetCDF file\n",
    "CMDI_ds = nc.Dataset(CMDI_file, 'w', format='NETCDF4')\n",
    "\n",
    "# Define dimensions\n",
    "time_dim = CMDI_ds.createDimension('time', 264)\n",
    "lat_dim = CMDI_ds.createDimension('lat', 721)\n",
    "lon_dim = CMDI_ds.createDimension('lon', 1441)\n",
    "\n",
    "# Create variables\n",
    "time_var = CMDI_ds.createVariable('time', np.float64, ('time',))\n",
    "lat_var = CMDI_ds.createVariable('lat', np.float64, ('lat',))\n",
    "lon_var = CMDI_ds.createVariable('lon', np.float64, ('lon',))\n",
    "CMDI_var = CMDI_ds.createVariable('CMDI', np.float64, ('time', 'lat', 'lon',), fill_value=np.nan)\n",
    "\n",
    "# Assign attributes\n",
    "time_var.units = \"days since 2000-01-31\"\n",
    "time_var.calendar = \"proleptic_gregorian\"\n",
    "lat_var.units = \"degrees_north\"\n",
    "lon_var.units = \"degrees_east\"\n",
    "\n",
    "# Read data from the source files\n",
    "time_data = mRAI_ds.variables['time'][:]\n",
    "lat_data = mRAI_ds.variables['lat'][:]\n",
    "lon_data = mRAI_ds.variables['lon'][:]\n",
    "mRAI_data = mRAI_ds.variables['mRAI_weighted'][:]\n",
    "\n",
    "# Handle different dimensions for mMRA2\n",
    "mMRA2_data_resized = np.full((264, 721, 1441), np.nan)\n",
    "mMRA2_data = mMRA2_ds.variables['mMRA2_weighted'][:]\n",
    "\n",
    "# Resize mMRA2 data to match the dimensions of other datasets\n",
    "for t in range(263):\n",
    "    mMRA2_data_resized[t, :720, :1440] = mMRA2_data[t, :, :]\n",
    "\n",
    "MI_data = MI_ds.variables['MI_weighted'][:]\n",
    "\n",
    "# Combine the data\n",
    "CMDI_data = mRAI_data + mMRA2_data_resized + MI_data\n",
    "\n",
    "# Assign data to variables\n",
    "time_var[:] = time_data\n",
    "lat_var[:] = lat_data\n",
    "lon_var[:] = lon_data\n",
    "CMDI_var[:] = CMDI_data\n",
    "\n",
    "# Close the datasets\n",
    "mRAI_ds.close()\n",
    "mMRA2_ds.close()\n",
    "MI_ds.close()\n",
    "CMDI_ds.close()\n",
    "\n",
    "print(\"New NetCDF file CMDI.nc created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8c6759-3fd9-4b1a-9d5c-f1077cf22d22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
